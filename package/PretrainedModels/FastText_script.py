import numpy as np
from helpers.utilities import (calculate_cosine_similarity,
                               convert_to_sentence_vector)


def infer_fasttext(text_1,text_2):
      
    ######################################################################################################
    # Path to the downloaded pretrained FastText Vector file. The wiki-news-300d-1M-subword.vec is a
    # 1 million word vectors trained with subword infomation on Wikipedia 2017, UMBC webbase corpus and 
    # statmt.org news dataset (16B tokens). Each word/subword is a 300 dimension vector. The file
    # is in the following format:
    #
    # the 0.0129 0.0026 0.0098 0.0063 0.0102 -0.0002 -0.0056 -0.0829 -0.0420 0.0064 -0.0086 -0.0785 0.0148
    # 0.0099 -0.0041 0.0127 0.0706 -0.0017 0.0577 0.0140 -0.0073 -0.0082 0.0047 0.0336 0.0100 -0.0024 
    # 0.0135 0.0061 0.0939 0.0103 -0.0088 0.0092 0.0072 -0.0317 -0.0562 -0.0387 -0.0038 -0.0036 -0.0013 
    # -0.0157 0.0009 -0.0091 -0.0141 0.0052 -0.0040 0.0379 0.0045 -0.0047 -0.0172 -0.0038 0.0048 -0.0008 
    # -0.0090 0.0155 -0.0080 0.0041 -0.0086 -0.0149 -0.0734 0.0007 0.0103 0.0004 0.1226 -0.0018 -0.0023 
    # 0.0095 0.0069 -0.0076 0.0092 0.0069 -0.0094 -0.0147 -0.0229 0.0111 0.0067 0.0044 -0.0056 0.0333 
    # -0.0104 0.0048 -0.0173 0.0364 -0.0167 0.0562 0.0043 0.0029 0.0005 -0.0642 -0.0087 -0.0100 -0.0209 
    # -0.0233 -0.0960 -0.0271 0.0026 0.0321 0.0110 -0.0157 0.0131 0.0051 0.0001 0.0050 0.0203 0.0192 
    # -0.0097 -0.1351 0.0011 -0.0039 0.0079 0.0050 0.0007 0.0576 0.0559 -0.0066 -0.0054 0.0046 -0.0100 
    # -0.0009 -0.0402 0.0076 0.0130 0.0122 0.0028 0.0170 -0.1228 -0.0106 0.0053 -0.1456 0.0037 0.1202 
    # 0.0159 0.0208 -0.0035 0.0073 0.0254 0.0035 -0.0085 0.0662 0.0122 0.0006 -0.0047 0.0062 0.0013 
    # -0.0076 -0.0134 0.0038 0.0013 0.0051 -0.0027 0.0076 -0.0036 0.0093 -0.0035 -0.0319 0.0287 -0.0167 
    # 0.0065 -0.0032 -0.0010 0.0083 -0.0090 -0.0167 0.0024 -0.0068 0.0122 -0.0065 -0.0003 -0.0034 0.0029 
    # -0.0031 0.0011 -0.0099 0.0025 0.0062 0.0026 0.0045 -0.0029 0.0192 -0.0126 0.0024 -0.0082 0.0111 
    # 0.0096 -0.0191 -0.0106 -0.0187 0.0027 0.1193 0.0153 -0.0053 0.0044 0.1007 -0.0522 -0.0027 0.0013 
    # 0.0090 0.0105 0.0088 -0.0008 0.0087 -0.1102 0.0473 0.0037 -0.0044 -0.0080 -0.0115 0.0043 0.0021 
    # 0.0077 0.0322 0.1404 0.0014 0.0163 -0.0047 0.0257 0.0141 0.0210 0.0161 0.0141 -0.0222 0.0050 -0.0114 
    # -0.0096 0.0908 -0.0031 0.0015 0.0052 0.0454 0.0054 -0.0041 0.0120 -0.0774 -0.0504 -0.0110 0.0029 
    # 0.0098 -0.0097 -0.0093 -0.0060 -0.0081 0.0669 0.0084 -0.0062 0.0030 -0.1998 -0.0039 -0.0113 -0.0053 
    # 0.0005 -0.0364 0.0302 0.0088 0.0159 0.0172 -0.0227 0.0008 -0.0077 0.0302 -0.0163 0.0027 -0.0094 
    # -0.0112 -0.0057 -0.0252 0.0038 0.0060 -0.0092 -0.0239 -0.0027 0.0082 0.0078 0.0903 -0.1246 -0.0256 
    # 0.0558 -0.0565 -0.0033 0.0046 0.0092 -0.0176 0.0538 0.0099 0.0113 -0.0019 0.0738 -0.0035 -0.0380 
    # -0.0967 0.0028 0.0027 -0.0066 0.0213 0.0053 0.0097 -0.0035 -0.0046 -0.0099 -0.0186 0.0098 0.0019
    ########################################################################################################
    
    vocab_vector_file = './package/PretrainedModels/models/wiki-news-300d-1M-subword.vec'

    embeddings_matrix = dict()

    # Converting the vector file into a dictionary format with tokens as key and vector as value.
    with open(vocab_vector_file,'r') as file:
        for line in file:
            values = line.split()
            word = values[0]
            coefs = np.asarray(values[1:], dtype='float32')
            embeddings_matrix[word] = coefs

    # Converting word vectors to sentence vectors
    sentence_vector_1 = convert_to_sentence_vector(text_1,embeddings_matrix)
    sentence_vector_2 = convert_to_sentence_vector(text_2,embeddings_matrix)

    # Calculating the cosine similarity between the two sentence vectors
    similarity_score = calculate_cosine_similarity(sentence_vector_1,
                                                   sentence_vector_2)[0][0]

    return('Cosine Similarity between _{0}_ and _{1}_ is **{2}**'.format(text_1,
                                                                         text_2,
                                                                         similarity_score))
